{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# from https://www.kaggle.com/chmaxx/finetune-vgg16-0-97-with-minimal-effort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input, decode_predictions\n",
    "\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.options.display.max_rows = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg16 = VGG16(weights = 'imagenet',include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "=================================================================\n",
      "Total params: 14,714,688.0\n",
      "Trainable params: 14,714,688.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg16.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = vgg16.get_layer('block5_conv3').output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model_final = Model(inputs=vgg16.input, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for layer in vgg16.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model_final.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 14,846,273.0\n",
      "Trainable params: 131,585.0\n",
      "Non-trainable params: 14,714,688.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_final.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You need to have these three folders each with two subfolders for the two classes.\n",
    "train_data_dir = \"data/train\"\n",
    "validation_data_dir = \"data/valid\"\n",
    "test_data_dir = \"data/test\"\n",
    "\n",
    "batch_size = 5 # i achieved good and fast results with this small minibatch size for training\n",
    "batch_size_val = 5 # if Tensorflow throws a memory error while validating at end of epoch, decrease validation batch size her\n",
    "\n",
    "# set data augmentation parameters here\n",
    "datagen = ImageDataGenerator( \n",
    "    featurewise_center            = True,\n",
    "    rescale                       = 1.,\n",
    "    rotation_range                = 10,\n",
    "    width_shift_range             = .1,\n",
    "    height_shift_range            = .1,\n",
    "    shear_range                   = 0.2,\n",
    "    zoom_range                    = 0.2,\n",
    "    horizontal_flip               = True,\n",
    "    vertical_flip                 = False,\n",
    "    fill_mode                     = \"reflect\")\n",
    "\n",
    "# normalization neccessary for correct image input to VGG16\n",
    "datagen.mean=np.array([103.939, 116.779, 123.68],dtype=np.float32).reshape(1,1,3)\n",
    "\n",
    "# no data augmentation for validation and test set\n",
    "validgen = ImageDataGenerator(rescale=1., featurewise_center=True)\n",
    "validgen.mean=np.array([103.939, 116.779, 123.68],dtype=np.float32).reshape(1,1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1833 images belonging to 2 classes.\n",
      "Found 462 images belonging to 2 classes.\n",
      "Found 1531 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "# 600/450 _ 500/375 _ 400/300 _ 300/225\n",
    "\n",
    "img_width = 300  # Change image size for training here\n",
    "img_height = 225 # Change image size for training here\n",
    "\n",
    "train_gen = datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=\"binary\",\n",
    "        shuffle=True, \n",
    "        #save_to_dir=\"_augmented_images/\", \n",
    "        #save_prefix=\"aug_\"\n",
    "        )\n",
    "\n",
    "val_gen = validgen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=\"binary\",\n",
    "        shuffle=True)\n",
    "\n",
    "test_gen = validgen.flow_from_directory(\n",
    "        test_data_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=1,\n",
    "        class_mode=\"binary\",\n",
    "        shuffle=False)\n",
    "\n",
    "train_samples = len(train_gen.filenames)\n",
    "validation_samples = len(val_gen.filenames)\n",
    "test_samples = len(test_gen.filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a2b886eae8943e69cdb8030f4cde34a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de06cf98260349e0b73816e90205fdf5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d2415e69ca045a08e996e646a705744"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2384151c10e467da9e7ec1bd9bf310f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a178bc864f0497a95bd5da95a4b6572"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f505032885d4dbc831fd678c71af651"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0351f585e0641ccb90a3fbe3bb5a828"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29813d57aa854feb8b83469139b3d183"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b58973905b647a189c4251c0fb069fa"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47ac210bd4384337a8b2ad55e10b3e59"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00008: early stopping\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fca1c345240>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "\n",
    "# \"_tf_logs\" is my Tensorboard folder. Change this to your setup if you want to use TB\n",
    "logdir = \"_tf_logs/\" + now.strftime(\"%Y%m%d-%H%M%S\") + \"/\"\n",
    "tb = TensorBoard(log_dir=logdir)\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"weights-1-{epoch:02d}-{val_acc:.2f}.hdf5\",\n",
    "                             monitor='val_acc',\n",
    "                             verbose=0,\n",
    "                             save_best_only=False,\n",
    "                             save_weights_only=True)\n",
    "\n",
    "epochs=10\n",
    "\n",
    "# I stopped training automagically with EarlyStopping after 3 consecutive epochs without improvement\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1, mode='auto')\n",
    "\n",
    "model_final.fit_generator(train_gen, epochs=epochs, \n",
    "                          steps_per_epoch=int(train_samples/batch_size), \n",
    "                          validation_data=val_gen, \n",
    "                          validation_steps=batch_size_val, \n",
    "                          verbose=0, callbacks=[early_stopping, tb, TQDMNotebookCallback(), checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1833 images belonging to 2 classes.\n",
      "Found 462 images belonging to 2 classes.\n",
      "Found 1531 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "# 600/450 _ 500/375 _ 400/300 _ 300/225\n",
    "\n",
    "img_width = 600  # Change image size for training here\n",
    "img_height = 450 # Change image size for training here\n",
    "\n",
    "train_gen = datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=\"binary\",\n",
    "        shuffle=True, \n",
    "        #save_to_dir=\"_augmented_images/\", \n",
    "        #save_prefix=\"aug_\"\n",
    "        )\n",
    "\n",
    "val_gen = validgen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=\"binary\",\n",
    "        shuffle=True)\n",
    "\n",
    "test_gen = validgen.flow_from_directory(\n",
    "        test_data_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=1,\n",
    "        class_mode=\"binary\",\n",
    "        shuffle=False)\n",
    "\n",
    "train_samples = len(train_gen.filenames)\n",
    "validation_samples = len(val_gen.filenames)\n",
    "test_samples = len(test_gen.filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46661d81afa14cd48c19485255e53bd2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bfe4bcaa5f54a6691fceb98957cd462"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2a5576f1387424f8ab79f9719e47524"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb5e71b991c245169a841a946143a7ee"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1abe2edfdecc40b595666c18ff10240d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d99fcbae4db6449fbf7fd22c99cc73a7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c1237f6beaa4772b58e10ac8db47d3b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00005: early stopping\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fca1c32aef0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "\n",
    "# \"_tf_logs\" is my Tensorboard folder. Change this to your setup if you want to use TB\n",
    "logdir = \"_tf_logs/\" + now.strftime(\"%Y%m%d-%H%M%S\") + \"/\"\n",
    "tb = TensorBoard(log_dir=logdir)\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"weights-2-{epoch:02d}-{val_acc:.2f}.hdf5\",\n",
    "                             monitor='val_acc',\n",
    "                             verbose=0,\n",
    "                             save_best_only=False,\n",
    "                             save_weights_only=True)\n",
    "\n",
    "epochs=10\n",
    "\n",
    "# I stopped training automagically with EarlyStopping after 3 consecutive epochs without improvement\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1, mode='auto')\n",
    "\n",
    "model_final.fit_generator(train_gen, epochs=epochs, \n",
    "                          steps_per_epoch=int(train_samples/batch_size), \n",
    "                          validation_data=val_gen, \n",
    "                          validation_steps=batch_size_val, \n",
    "                          verbose=0, callbacks=[early_stopping, tb, TQDMNotebookCallback(), checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_1\n",
      "1 block1_conv1\n",
      "2 block1_conv2\n",
      "3 block1_pool\n",
      "4 block2_conv1\n",
      "5 block2_conv2\n",
      "6 block2_pool\n",
      "7 block3_conv1\n",
      "8 block3_conv2\n",
      "9 block3_conv3\n",
      "10 block3_pool\n",
      "11 block4_conv1\n",
      "12 block4_conv2\n",
      "13 block4_conv3\n",
      "14 block4_pool\n",
      "15 block5_conv1\n",
      "16 block5_conv2\n",
      "17 block5_conv3\n",
      "18 global_average_pooling2d_1\n",
      "19 dense_1\n",
      "20 dropout_1\n",
      "21 dense_2\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(model_final.layers):\n",
    "   print(i, layer.name)\n",
    "\n",
    "for layer in model_final.layers[:15]:\n",
    "   layer.trainable = False\n",
    "for layer in model_final.layers[15:]:\n",
    "   layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_final.compile(optimizer=SGD(lr=0.0001, momentum=0.9, nesterov=True),  loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a6fa3d911a14f02975f6971fb79b4cb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9172317800124bdfa0444ffafb07b76f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e578b547249546a3ad4453ba934afa54"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c64e575afa134014b7598a74d3854f6e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9c2a37643f349afbc38ef51308f5a75"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c3050273f0b4842b668f667ed9d29aa"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "457bc996a55d4100b1b69cdfe048735d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47c3dda82d2c4dba9f4553c5ca3aa380"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78d3f6e2c6464cc6a0bdb399e191c3a4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "359d7346017c4bb8b89e36ef1b574617"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00008: early stopping\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fca194806d8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "\n",
    "# \"_tf_logs\" is my Tensorboard folder. Change this to your setup if you want to use TB\n",
    "logdir = \"_tf_logs/\" + now.strftime(\"%Y%m%d-%H%M%S\") + \"/\"\n",
    "tb = TensorBoard(log_dir=logdir)\n",
    "\n",
    "epochs=50\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1, mode='auto')\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"weights-3-{epoch:02d}-{val_acc:.2f}.hdf5\",\n",
    "                             monitor='val_acc',\n",
    "                             verbose=0,\n",
    "                             save_best_only=False,\n",
    "                             save_weights_only=True)\n",
    "\n",
    "model_final.fit_generator(train_gen, epochs=epochs, \n",
    "                          steps_per_epoch=int(train_samples/batch_size), \n",
    "                          validation_data=val_gen, \n",
    "                          validation_steps=int(validation_samples/batch_size), \n",
    "                          verbose=0, callbacks=[early_stopping, tb, TQDMNotebookCallback(), checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = model_final.predict_generator(test_gen, 1531)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.00000000e+00],\n",
       "       [  1.00000000e+00],\n",
       "       [  1.00000000e+00],\n",
       "       ..., \n",
       "       [  4.41600643e-02],\n",
       "       [  7.95541564e-06],\n",
       "       [  8.34533479e-03]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds_filenames = test_gen.filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_filenames = [int(x.replace(\"unknown/\", \"\").replace(\".jpg\", \"\")) for x in preds_filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1054,\n",
       " 639,\n",
       " 691,\n",
       " 1244,\n",
       " 19,\n",
       " 584,\n",
       " 113,\n",
       " 692,\n",
       " 411,\n",
       " 813,\n",
       " 750,\n",
       " 462,\n",
       " 124,\n",
       " 819,\n",
       " 985,\n",
       " 838,\n",
       " 99,\n",
       " 1044,\n",
       " 688,\n",
       " 489,\n",
       " 261,\n",
       " 1265,\n",
       " 508,\n",
       " 497,\n",
       " 612,\n",
       " 1348,\n",
       " 271,\n",
       " 1319,\n",
       " 942,\n",
       " 892,\n",
       " 618,\n",
       " 1288,\n",
       " 1476,\n",
       " 491,\n",
       " 1349,\n",
       " 244,\n",
       " 521,\n",
       " 386,\n",
       " 909,\n",
       " 518,\n",
       " 587,\n",
       " 199,\n",
       " 103,\n",
       " 120,\n",
       " 1026,\n",
       " 862,\n",
       " 1010,\n",
       " 880,\n",
       " 1123,\n",
       " 335,\n",
       " 370,\n",
       " 503,\n",
       " 617,\n",
       " 231,\n",
       " 509,\n",
       " 1367,\n",
       " 927,\n",
       " 1037,\n",
       " 474,\n",
       " 1383,\n",
       " 1018,\n",
       " 163,\n",
       " 1030,\n",
       " 356,\n",
       " 1110,\n",
       " 764,\n",
       " 893,\n",
       " 758,\n",
       " 658,\n",
       " 308,\n",
       " 1119,\n",
       " 149,\n",
       " 71,\n",
       " 1338,\n",
       " 412,\n",
       " 1129,\n",
       " 1284,\n",
       " 239,\n",
       " 1260,\n",
       " 77,\n",
       " 1421,\n",
       " 1360,\n",
       " 1093,\n",
       " 1187,\n",
       " 341,\n",
       " 66,\n",
       " 1426,\n",
       " 374,\n",
       " 490,\n",
       " 1515,\n",
       " 1279,\n",
       " 565,\n",
       " 1336,\n",
       " 983,\n",
       " 1529,\n",
       " 416,\n",
       " 1305,\n",
       " 613,\n",
       " 1394,\n",
       " 695,\n",
       " 1239,\n",
       " 218,\n",
       " 109,\n",
       " 948,\n",
       " 388,\n",
       " 863,\n",
       " 184,\n",
       " 916,\n",
       " 1116,\n",
       " 287,\n",
       " 286,\n",
       " 1041,\n",
       " 535,\n",
       " 453,\n",
       " 1247,\n",
       " 1192,\n",
       " 311,\n",
       " 905,\n",
       " 773,\n",
       " 171,\n",
       " 17,\n",
       " 1153,\n",
       " 1229,\n",
       " 476,\n",
       " 1403,\n",
       " 908,\n",
       " 596,\n",
       " 1004,\n",
       " 721,\n",
       " 818,\n",
       " 1453,\n",
       " 270,\n",
       " 414,\n",
       " 1106,\n",
       " 1201,\n",
       " 1330,\n",
       " 1157,\n",
       " 316,\n",
       " 1402,\n",
       " 1370,\n",
       " 1084,\n",
       " 1342,\n",
       " 976,\n",
       " 1112,\n",
       " 502,\n",
       " 623,\n",
       " 886,\n",
       " 92,\n",
       " 479,\n",
       " 1356,\n",
       " 330,\n",
       " 1361,\n",
       " 1050,\n",
       " 904,\n",
       " 1258,\n",
       " 578,\n",
       " 918,\n",
       " 12,\n",
       " 684,\n",
       " 708,\n",
       " 1285,\n",
       " 661,\n",
       " 45,\n",
       " 1363,\n",
       " 891,\n",
       " 1436,\n",
       " 776,\n",
       " 789,\n",
       " 712,\n",
       " 486,\n",
       " 686,\n",
       " 340,\n",
       " 1215,\n",
       " 1499,\n",
       " 501,\n",
       " 1434,\n",
       " 1460,\n",
       " 1051,\n",
       " 986,\n",
       " 672,\n",
       " 258,\n",
       " 1067,\n",
       " 935,\n",
       " 204,\n",
       " 1327,\n",
       " 401,\n",
       " 1461,\n",
       " 648,\n",
       " 1078,\n",
       " 812,\n",
       " 138,\n",
       " 365,\n",
       " 1068,\n",
       " 221,\n",
       " 967,\n",
       " 815,\n",
       " 949,\n",
       " 1372,\n",
       " 1292,\n",
       " 1074,\n",
       " 643,\n",
       " 767,\n",
       " 593,\n",
       " 884,\n",
       " 910,\n",
       " 1464,\n",
       " 507,\n",
       " 1070,\n",
       " 445,\n",
       " 125,\n",
       " 253,\n",
       " 899,\n",
       " 1065,\n",
       " 557,\n",
       " 318,\n",
       " 693,\n",
       " 202,\n",
       " 40,\n",
       " 1325,\n",
       " 175,\n",
       " 524,\n",
       " 173,\n",
       " 372,\n",
       " 1158,\n",
       " 1191,\n",
       " 188,\n",
       " 1049,\n",
       " 1471,\n",
       " 1430,\n",
       " 203,\n",
       " 185,\n",
       " 822,\n",
       " 1302,\n",
       " 187,\n",
       " 53,\n",
       " 51,\n",
       " 1085,\n",
       " 145,\n",
       " 641,\n",
       " 901,\n",
       " 176,\n",
       " 732,\n",
       " 690,\n",
       " 9,\n",
       " 937,\n",
       " 395,\n",
       " 795,\n",
       " 1312,\n",
       " 1478,\n",
       " 667,\n",
       " 1171,\n",
       " 666,\n",
       " 1071,\n",
       " 522,\n",
       " 15,\n",
       " 18,\n",
       " 46,\n",
       " 1058,\n",
       " 4,\n",
       " 1347,\n",
       " 745,\n",
       " 845,\n",
       " 595,\n",
       " 1076,\n",
       " 1427,\n",
       " 1189,\n",
       " 1455,\n",
       " 1257,\n",
       " 1290,\n",
       " 1125,\n",
       " 79,\n",
       " 797,\n",
       " 1089,\n",
       " 896,\n",
       " 1052,\n",
       " 214,\n",
       " 1522,\n",
       " 126,\n",
       " 1366,\n",
       " 1339,\n",
       " 1056,\n",
       " 436,\n",
       " 828,\n",
       " 1022,\n",
       " 1369,\n",
       " 739,\n",
       " 1405,\n",
       " 601,\n",
       " 1114,\n",
       " 1380,\n",
       " 989,\n",
       " 212,\n",
       " 1218,\n",
       " 432,\n",
       " 128,\n",
       " 213,\n",
       " 895,\n",
       " 1161,\n",
       " 837,\n",
       " 260,\n",
       " 1077,\n",
       " 945,\n",
       " 1100,\n",
       " 1412,\n",
       " 788,\n",
       " 970,\n",
       " 611,\n",
       " 359,\n",
       " 736,\n",
       " 1466,\n",
       " 1196,\n",
       " 376,\n",
       " 1465,\n",
       " 325,\n",
       " 1303,\n",
       " 1271,\n",
       " 332,\n",
       " 820,\n",
       " 843,\n",
       " 605,\n",
       " 876,\n",
       " 399,\n",
       " 727,\n",
       " 1310,\n",
       " 1082,\n",
       " 715,\n",
       " 1204,\n",
       " 1437,\n",
       " 290,\n",
       " 1159,\n",
       " 283,\n",
       " 114,\n",
       " 600,\n",
       " 496,\n",
       " 20,\n",
       " 706,\n",
       " 135,\n",
       " 112,\n",
       " 43,\n",
       " 573,\n",
       " 887,\n",
       " 494,\n",
       " 957,\n",
       " 1073,\n",
       " 626,\n",
       " 1083,\n",
       " 1385,\n",
       " 481,\n",
       " 516,\n",
       " 906,\n",
       " 1429,\n",
       " 48,\n",
       " 979,\n",
       " 1346,\n",
       " 119,\n",
       " 352,\n",
       " 1504,\n",
       " 157,\n",
       " 1081,\n",
       " 360,\n",
       " 620,\n",
       " 1087,\n",
       " 190,\n",
       " 358,\n",
       " 650,\n",
       " 1262,\n",
       " 694,\n",
       " 506,\n",
       " 336,\n",
       " 810,\n",
       " 978,\n",
       " 1225,\n",
       " 1105,\n",
       " 1246,\n",
       " 1406,\n",
       " 1012,\n",
       " 823,\n",
       " 464,\n",
       " 817,\n",
       " 118,\n",
       " 186,\n",
       " 274,\n",
       " 842,\n",
       " 680,\n",
       " 606,\n",
       " 768,\n",
       " 54,\n",
       " 1469,\n",
       " 977,\n",
       " 1408,\n",
       " 1485,\n",
       " 919,\n",
       " 237,\n",
       " 807,\n",
       " 31,\n",
       " 853,\n",
       " 275,\n",
       " 821,\n",
       " 384,\n",
       " 922,\n",
       " 562,\n",
       " 442,\n",
       " 1140,\n",
       " 1047,\n",
       " 1506,\n",
       " 169,\n",
       " 179,\n",
       " 1096,\n",
       " 7,\n",
       " 431,\n",
       " 309,\n",
       " 1411,\n",
       " 1228,\n",
       " 423,\n",
       " 1375,\n",
       " 380,\n",
       " 1390,\n",
       " 480,\n",
       " 855,\n",
       " 866,\n",
       " 1331,\n",
       " 956,\n",
       " 1520,\n",
       " 512,\n",
       " 499,\n",
       " 303,\n",
       " 550,\n",
       " 1126,\n",
       " 104,\n",
       " 917,\n",
       " 981,\n",
       " 1203,\n",
       " 254,\n",
       " 1300,\n",
       " 1251,\n",
       " 1531,\n",
       " 1435,\n",
       " 1086,\n",
       " 153,\n",
       " 225,\n",
       " 437,\n",
       " 829,\n",
       " 1525,\n",
       " 1256,\n",
       " 731,\n",
       " 357,\n",
       " 675,\n",
       " 646,\n",
       " 784,\n",
       " 375,\n",
       " 1111,\n",
       " 236,\n",
       " 599,\n",
       " 234,\n",
       " 982,\n",
       " 1120,\n",
       " 1417,\n",
       " 687,\n",
       " 242,\n",
       " 1156,\n",
       " 164,\n",
       " 345,\n",
       " 849,\n",
       " 1253,\n",
       " 854,\n",
       " 215,\n",
       " 30,\n",
       " 144,\n",
       " 1395,\n",
       " 13,\n",
       " 525,\n",
       " 1523,\n",
       " 299,\n",
       " 993,\n",
       " 801,\n",
       " 463,\n",
       " 966,\n",
       " 447,\n",
       " 542,\n",
       " 928,\n",
       " 1304,\n",
       " 362,\n",
       " 783,\n",
       " 377,\n",
       " 247,\n",
       " 1424,\n",
       " 791,\n",
       " 558,\n",
       " 262,\n",
       " 1104,\n",
       " 1320,\n",
       " 1519,\n",
       " 718,\n",
       " 418,\n",
       " 924,\n",
       " 1240,\n",
       " 1057,\n",
       " 243,\n",
       " 710,\n",
       " 603,\n",
       " 625,\n",
       " 1019,\n",
       " 291,\n",
       " 140,\n",
       " 574,\n",
       " 235,\n",
       " 857,\n",
       " 1167,\n",
       " 1190,\n",
       " 1407,\n",
       " 548,\n",
       " 21,\n",
       " 346,\n",
       " 657,\n",
       " 1233,\n",
       " 1311,\n",
       " 633,\n",
       " 1216,\n",
       " 27,\n",
       " 1205,\n",
       " 137,\n",
       " 1516,\n",
       " 177,\n",
       " 1025,\n",
       " 511,\n",
       " 1000,\n",
       " 770,\n",
       " 676,\n",
       " 1214,\n",
       " 652,\n",
       " 790,\n",
       " 83,\n",
       " 939,\n",
       " 1277,\n",
       " 451,\n",
       " 288,\n",
       " 1482,\n",
       " 279,\n",
       " 111,\n",
       " 930,\n",
       " 88,\n",
       " 1149,\n",
       " 310,\n",
       " 95,\n",
       " 1117,\n",
       " 662,\n",
       " 951,\n",
       " 207,\n",
       " 321,\n",
       " 26,\n",
       " 528,\n",
       " 1016,\n",
       " 385,\n",
       " 678,\n",
       " 640,\n",
       " 852,\n",
       " 285,\n",
       " 1446,\n",
       " 1487,\n",
       " 284,\n",
       " 1365,\n",
       " 312,\n",
       " 1099,\n",
       " 146,\n",
       " 495,\n",
       " 1220,\n",
       " 406,\n",
       " 482,\n",
       " 840,\n",
       " 1115,\n",
       " 941,\n",
       " 1410,\n",
       " 1035,\n",
       " 456,\n",
       " 1024,\n",
       " 1032,\n",
       " 342,\n",
       " 1122,\n",
       " 415,\n",
       " 355,\n",
       " 802,\n",
       " 515,\n",
       " 1226,\n",
       " 785,\n",
       " 252,\n",
       " 1374,\n",
       " 1428,\n",
       " 830,\n",
       " 470,\n",
       " 130,\n",
       " 91,\n",
       " 1033,\n",
       " 805,\n",
       " 629,\n",
       " 1154,\n",
       " 771,\n",
       " 621,\n",
       " 59,\n",
       " 69,\n",
       " 582,\n",
       " 1484,\n",
       " 467,\n",
       " 1415,\n",
       " 301,\n",
       " 339,\n",
       " 105,\n",
       " 240,\n",
       " 1039,\n",
       " 246,\n",
       " 747,\n",
       " 683,\n",
       " 580,\n",
       " 1488,\n",
       " 615,\n",
       " 1521,\n",
       " 1069,\n",
       " 60,\n",
       " 1066,\n",
       " 304,\n",
       " 1447,\n",
       " 1188,\n",
       " 850,\n",
       " 1386,\n",
       " 1513,\n",
       " 34,\n",
       " 222,\n",
       " 1414,\n",
       " 227,\n",
       " 913,\n",
       " 1021,\n",
       " 1005,\n",
       " 67,\n",
       " 152,\n",
       " 1038,\n",
       " 1448,\n",
       " 492,\n",
       " 914,\n",
       " 581,\n",
       " 653,\n",
       " 627,\n",
       " 752,\n",
       " 1340,\n",
       " 794,\n",
       " 1337,\n",
       " 191,\n",
       " 844,\n",
       " 867,\n",
       " 182,\n",
       " 90,\n",
       " 944,\n",
       " 263,\n",
       " 749,\n",
       " 929,\n",
       " 1263,\n",
       " 777,\n",
       " 570,\n",
       " 28,\n",
       " 1075,\n",
       " 943,\n",
       " 1264,\n",
       " 984,\n",
       " 725,\n",
       " 1470,\n",
       " 946,\n",
       " 1098,\n",
       " 1368,\n",
       " 1178,\n",
       " 1183,\n",
       " 934,\n",
       " 500,\n",
       " 331,\n",
       " 326,\n",
       " 514,\n",
       " 1121,\n",
       " 392,\n",
       " 1473,\n",
       " 122,\n",
       " 990,\n",
       " 954,\n",
       " 546,\n",
       " 23,\n",
       " 689,\n",
       " 1454,\n",
       " 539,\n",
       " 483,\n",
       " 319,\n",
       " 1442,\n",
       " 1281,\n",
       " 925,\n",
       " 477,\n",
       " 1278,\n",
       " 637,\n",
       " 972,\n",
       " 1060,\n",
       " 70,\n",
       " 1212,\n",
       " 1207,\n",
       " 366,\n",
       " 964,\n",
       " 645,\n",
       " 1200,\n",
       " 1219,\n",
       " 724,\n",
       " 523,\n",
       " 219,\n",
       " 532,\n",
       " 413,\n",
       " 150,\n",
       " 1422,\n",
       " 1079,\n",
       " 81,\n",
       " 1127,\n",
       " 1315,\n",
       " 536,\n",
       " 545,\n",
       " 350,\n",
       " 1034,\n",
       " 711,\n",
       " 196,\n",
       " 108,\n",
       " 531,\n",
       " 513,\n",
       " 559,\n",
       " 995,\n",
       " 473,\n",
       " 409,\n",
       " 1152,\n",
       " 273,\n",
       " 757,\n",
       " 1211,\n",
       " 1236,\n",
       " 774,\n",
       " 241,\n",
       " 781,\n",
       " 446,\n",
       " 519,\n",
       " 671,\n",
       " 132,\n",
       " 452,\n",
       " 1197,\n",
       " 1231,\n",
       " 888,\n",
       " 226,\n",
       " 632,\n",
       " 1530,\n",
       " 1433,\n",
       " 766,\n",
       " 577,\n",
       " 1270,\n",
       " 1496,\n",
       " 433,\n",
       " 276,\n",
       " 289,\n",
       " 756,\n",
       " 1184,\n",
       " 457,\n",
       " 836,\n",
       " 870,\n",
       " 698,\n",
       " 1174,\n",
       " 1382,\n",
       " 760,\n",
       " 568,\n",
       " 1351,\n",
       " 769,\n",
       " 1143,\n",
       " 825,\n",
       " 228,\n",
       " 266,\n",
       " 851,\n",
       " 1095,\n",
       " 1425,\n",
       " 871,\n",
       " 1333,\n",
       " 962,\n",
       " 277,\n",
       " 1027,\n",
       " 742,\n",
       " 1248,\n",
       " 493,\n",
       " 1388,\n",
       " 1163,\n",
       " 85,\n",
       " 322,\n",
       " 1462,\n",
       " 1128,\n",
       " 1013,\n",
       " 1181,\n",
       " 1198,\n",
       " 459,\n",
       " 354,\n",
       " 1451,\n",
       " 1420,\n",
       " 1199,\n",
       " 860,\n",
       " 834,\n",
       " 314,\n",
       " 1468,\n",
       " 488,\n",
       " 302,\n",
       " 166,\n",
       " 400,\n",
       " 551,\n",
       " 1267,\n",
       " 107,\n",
       " 778,\n",
       " 156,\n",
       " 1173,\n",
       " 809,\n",
       " 642,\n",
       " 383,\n",
       " 1138,\n",
       " 1182,\n",
       " 1029,\n",
       " 520,\n",
       " 1242,\n",
       " 180,\n",
       " 586,\n",
       " 1322,\n",
       " 460,\n",
       " 441,\n",
       " 123,\n",
       " 194,\n",
       " 973,\n",
       " 378,\n",
       " 1014,\n",
       " 1107,\n",
       " 327,\n",
       " 1213,\n",
       " 1269,\n",
       " 1008,\n",
       " 407,\n",
       " 396,\n",
       " 1124,\n",
       " 209,\n",
       " 998,\n",
       " 832,\n",
       " 141,\n",
       " 737,\n",
       " 567,\n",
       " 162,\n",
       " 192,\n",
       " 471,\n",
       " 292,\n",
       " 440,\n",
       " 280,\n",
       " 701,\n",
       " 526,\n",
       " 1480,\n",
       " 992,\n",
       " 974,\n",
       " 429,\n",
       " 868,\n",
       " 1249,\n",
       " 1353,\n",
       " 900,\n",
       " 1423,\n",
       " 1508,\n",
       " 681,\n",
       " 673,\n",
       " 450,\n",
       " 1003,\n",
       " 38,\n",
       " 1490,\n",
       " 959,\n",
       " 201,\n",
       " 106,\n",
       " 664,\n",
       " 142,\n",
       " 1475,\n",
       " 926,\n",
       " 826,\n",
       " 32,\n",
       " 1036,\n",
       " 755,\n",
       " 554,\n",
       " 882,\n",
       " 859,\n",
       " 592,\n",
       " 1243,\n",
       " 281,\n",
       " 205,\n",
       " 1007,\n",
       " 1364,\n",
       " 1150,\n",
       " 1141,\n",
       " 6,\n",
       " 35,\n",
       " 1486,\n",
       " 631,\n",
       " 729,\n",
       " 590,\n",
       " 94,\n",
       " 181,\n",
       " 1329,\n",
       " 468,\n",
       " 333,\n",
       " 282,\n",
       " 37,\n",
       " 775,\n",
       " 216,\n",
       " 537,\n",
       " 1456,\n",
       " 232,\n",
       " 1326,\n",
       " 824,\n",
       " 738,\n",
       " 1396,\n",
       " 1416,\n",
       " 368,\n",
       " 449,\n",
       " 716,\n",
       " 1503,\n",
       " 733,\n",
       " 1309,\n",
       " 402,\n",
       " 861,\n",
       " 1328,\n",
       " 1493,\n",
       " 713,\n",
       " 373,\n",
       " 427,\n",
       " 841,\n",
       " 110,\n",
       " 121,\n",
       " 669,\n",
       " 1289,\n",
       " 1294,\n",
       " 11,\n",
       " 1,\n",
       " 1017,\n",
       " 265,\n",
       " 338,\n",
       " 347,\n",
       " 1440,\n",
       " 475,\n",
       " 129,\n",
       " 540,\n",
       " 965,\n",
       " 229,\n",
       " 1443,\n",
       " 1297,\n",
       " 1509,\n",
       " 1091,\n",
       " 1355,\n",
       " 589,\n",
       " 1381,\n",
       " 1130,\n",
       " 1409,\n",
       " 835,\n",
       " 210,\n",
       " 127,\n",
       " 134,\n",
       " 635,\n",
       " 1045,\n",
       " 1321,\n",
       " 1413,\n",
       " 1175,\n",
       " 571,\n",
       " 1232,\n",
       " 1389,\n",
       " 1391,\n",
       " 566,\n",
       " 465,\n",
       " 638,\n",
       " 387,\n",
       " 148,\n",
       " 97,\n",
       " 272,\n",
       " 1266,\n",
       " 1526,\n",
       " 1332,\n",
       " 1512,\n",
       " 323,\n",
       " 1209,\n",
       " 1477,\n",
       " 248,\n",
       " 96,\n",
       " 1344,\n",
       " 975,\n",
       " 1441,\n",
       " 208,\n",
       " 1080,\n",
       " 1400,\n",
       " 78,\n",
       " 1064,\n",
       " 206,\n",
       " 178,\n",
       " 1162,\n",
       " 420,\n",
       " 74,\n",
       " 1053,\n",
       " 167,\n",
       " 1527,\n",
       " 1009,\n",
       " 1002,\n",
       " 552,\n",
       " 1358,\n",
       " 389,\n",
       " 33,\n",
       " ...]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = pd.DataFrame({'name': preds_filenames, 'invasive': preds[:,0]})\n",
    "df_result = df_result.sort_values(\"name\")\n",
    "df_result.index = df_result[\"name\"]\n",
    "df_result = df_result.drop([\"name\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>invasive</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.468943e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.548811e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.622996e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.595422e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.378333e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7.763814e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.827941e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.667528e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3.905118e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7.400195e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>8.345335e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2.822479e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.911257e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>7.319626e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>6.475729e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1512</th>\n",
       "      <td>2.579722e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1513</th>\n",
       "      <td>7.884058e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1514</th>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1515</th>\n",
       "      <td>3.041243e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1516</th>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1517</th>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1518</th>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1519</th>\n",
       "      <td>4.564498e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1520</th>\n",
       "      <td>1.923507e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1521</th>\n",
       "      <td>3.764543e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1522</th>\n",
       "      <td>3.534232e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523</th>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524</th>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1525</th>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1526</th>\n",
       "      <td>9.326022e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1527</th>\n",
       "      <td>1.364230e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1528</th>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1529</th>\n",
       "      <td>1.461552e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1530</th>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1531</th>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1531 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          invasive\n",
       "name              \n",
       "1     1.000000e+00\n",
       "2     7.468943e-04\n",
       "3     9.548811e-02\n",
       "4     2.622996e-03\n",
       "5     1.000000e+00\n",
       "6     5.595422e-04\n",
       "7     5.378333e-02\n",
       "8     1.000000e+00\n",
       "9     1.000000e+00\n",
       "10    7.763814e-05\n",
       "11    2.827941e-06\n",
       "12    2.667528e-03\n",
       "13    3.905118e-03\n",
       "14    1.000000e+00\n",
       "15    7.400195e-04\n",
       "16    8.345335e-03\n",
       "17    2.822479e-04\n",
       "18    1.911257e-03\n",
       "19    7.319626e-05\n",
       "20    6.475729e-02\n",
       "...            ...\n",
       "1512  2.579722e-05\n",
       "1513  7.884058e-06\n",
       "1514  1.000000e+00\n",
       "1515  3.041243e-06\n",
       "1516  1.000000e+00\n",
       "1517  1.000000e+00\n",
       "1518  1.000000e+00\n",
       "1519  4.564498e-03\n",
       "1520  1.923507e-03\n",
       "1521  3.764543e-04\n",
       "1522  3.534232e-02\n",
       "1523  1.000000e+00\n",
       "1524  1.000000e+00\n",
       "1525  1.000000e+00\n",
       "1526  9.326022e-04\n",
       "1527  1.364230e-09\n",
       "1528  1.000000e+00\n",
       "1529  1.461552e-04\n",
       "1530  1.000000e+00\n",
       "1531  1.000000e+00\n",
       "\n",
       "[1531 rows x 1 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_result.to_csv(\"submission_01.csv\", encoding=\"utf8\", index=True) #0.98680"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_final.load_weights('./weights-1-02-1.00.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = model_final.predict_generator(test_gen, 1531)\n",
    "preds_filenames = test_gen.filenames\n",
    "preds_filenames = [int(x.replace(\"unknown/\", \"\").replace(\".jpg\", \"\")) for x in preds_filenames]\n",
    "df_result = pd.DataFrame({'name': preds_filenames, 'invasive': preds[:,0]})\n",
    "df_result = df_result.sort_values(\"name\")\n",
    "df_result.index = df_result[\"name\"]\n",
    "df_result = df_result.drop([\"name\"], axis=1)\n",
    "df_result.to_csv(\"submission_02.csv\", encoding=\"utf8\", index=True) #0.51792"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_final.load_weights('./weights-2-01-1.00.hdf5')\n",
    "preds = model_final.predict_generator(test_gen, 1531)\n",
    "preds_filenames = test_gen.filenames\n",
    "preds_filenames = [int(x.replace(\"unknown/\", \"\").replace(\".jpg\", \"\")) for x in preds_filenames]\n",
    "df_result = pd.DataFrame({'name': preds_filenames, 'invasive': preds[:,0]})\n",
    "df_result = df_result.sort_values(\"name\")\n",
    "df_result.index = df_result[\"name\"]\n",
    "df_result = df_result.drop([\"name\"], axis=1)\n",
    "df_result.to_csv(\"submission_03.csv\", encoding=\"utf8\", index=True) #0.52201"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
